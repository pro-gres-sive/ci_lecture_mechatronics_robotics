{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e2d7b7-0fa3-4dd8-b51f-016ea5c05a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #library for visualizing data\n",
    "%matplotlib widget \n",
    "#setting for jupyter lab\n",
    "plt.rcParams['figure.figsize'] = [12, 6] #setting figure size (plots)\n",
    "\n",
    "import pandas as pd  # (software library for data analysis and manipulation, https://pandas.pydata.org/docs/)\n",
    "import numpy as np  # (software library for matrix multiplications, https://numpy.org/doc/)\n",
    "import statistics as stats  # (python module for statistic calculations, https://docs.python.org/3/library/statistics.html)\n",
    "import time #python time module\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def tanh_deriv(x):\n",
    "    return 1 - x ** 2\n",
    "\n",
    "\n",
    "activations = {}\n",
    "\n",
    "\n",
    "class NeuralNet:\n",
    "\n",
    "    history = []\n",
    "    layer_topology = []\n",
    "\n",
    "    \n",
    "    \n",
    "    def __init__(self, layers, activation='tanh', print_model_info=True):\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = sigmoid\n",
    "            self.activation_prime = sigmoid_deriv\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = tanh\n",
    "            self.activation_prime = tanh_deriv\n",
    "\n",
    "        self.layers = layers\n",
    "\n",
    "        # Set weights for each layer\n",
    "        self.weights = []\n",
    "        for i in range(0, len(layers) - 1):\n",
    "            additional_column = 1 if i < len(layers) - 2 else 0\n",
    "            r = np.random.randint(-200, 200, (layers[i] + 1, layers[i + 1] + additional_column)) * 0.001\n",
    "            self.weights.append(r)\n",
    "\n",
    "        if print_model_info:\n",
    "            self.print_model_info()\n",
    "\n",
    "            \n",
    "            \n",
    "    def print_model_info(self):\n",
    "        print('Model: \\n')\n",
    "\n",
    "        layers = self.layers\n",
    "        max_nodes = max(layers)\n",
    "        for i, layer in enumerate(layers):\n",
    "            diff = abs(max_nodes - layer)\n",
    "            output = ''\n",
    "            for k in range(round(diff + 0.5 / 2)):\n",
    "                output += ' '\n",
    "            for j in range(layer):\n",
    "                output += ' O'\n",
    "            for k in range(round(diff + 5)):\n",
    "                output += ' '\n",
    "            if i == 0:\n",
    "                output += f'{layer} Input(s)'\n",
    "            elif i == len(layers) - 1:\n",
    "                output += f'{layer} Output(s)'\n",
    "            else:\n",
    "                output += f'{layer} Node(s)'\n",
    "            print(output)\n",
    "\n",
    "        print('\\nActivation:', str(self.activation))\n",
    "\n",
    "        weight_count = 0\n",
    "        for weight in self.weights:\n",
    "            weight_count += weight.shape[0] * weight.shape[1]\n",
    "\n",
    "        print(f'{len(layers)} Layers')\n",
    "        print(f'{weight_count} trainable parameters.\\n\\n')\n",
    "\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y, l_rate=0.2, epochs=100000, print_freq=100):\n",
    "        t_0 = time.perf_counter()\n",
    "\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.hstack((ones.T, X))  # stack ones for bias\n",
    "\n",
    "        history = []\n",
    "\n",
    "        for k in range(epochs):\n",
    "            t_0_epoch = time.perf_counter()\n",
    "            for i, row in enumerate(X):  # loop through every training data sample\n",
    "\n",
    "                # FEED FORWARD\n",
    "                layer_activations = [row]\n",
    "                for w_i in range(len(self.weights)):\n",
    "                    dot_value = np.matmul(layer_activations[w_i], self.weights[w_i])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    layer_activations.append(activation)\n",
    "\n",
    "                # 1: Output Layer\n",
    "                nn_result = layer_activations[-1]  # last item in our layer_activations is the output of our network\n",
    "                error = y[i] - nn_result\n",
    "\n",
    "                deltas = [error * self.activation_prime(layer_activations[-1])]\n",
    "\n",
    "                # 2: Backpropagation Hidden Layers\n",
    "                for la_i in range(len(layer_activations) - 2, 0, -1):  # iterate backwards through layer_activations and weights\n",
    "                    ##compute delta based on previous examined layers deltas and save in list\n",
    "                    #?\n",
    "                deltas.reverse()  # invert order of delta list\n",
    "\n",
    "                # 3: Gradient calculation and weight update\n",
    "                for w_i in range(len(self.weights)):\n",
    "                    layer_activation = np.atleast_2d(layer_activations[w_i])\n",
    "                    delta = np.atleast_2d(deltas[w_i])\n",
    "                    gradient = np.matmul(layer_activation.T, delta)\n",
    "                    self.weights[w_i] += l_rate * gradient\n",
    "\n",
    "            # performance control\n",
    "            Y_pred = nn.predict(X[:, 1:])\n",
    "            error = Y_pred - y.reshape(len(y), 1)\n",
    "            mse = (error ** 2).mean()\n",
    "            mae = np.abs(error).mean()\n",
    "\n",
    "            history.append([k, mse, mae])\n",
    "\n",
    "            # print output\n",
    "            #? add validation data\n",
    "            if k % print_freq == 0:\n",
    "                t_1_epoch = time.perf_counter()\n",
    "                time_delta_epochs = t_1_epoch - t_0_epoch\n",
    "                mean_time_delta_epochs_ms = round((time_delta_epochs / print_freq) * 1000, 4)\n",
    "                print(f'Epochs: {k}  -  MSE: {round(mse,4)}  -  MAE: {round(mae,4)}  -  Mean Time per Epoch: {mean_time_delta_epochs_ms} ms')\n",
    "\n",
    "        self.history = history\n",
    "        print(f'\\nTraining finished. Time consumed: {round(time.perf_counter() - t_0, 2)} s')\n",
    "        return history\n",
    "\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.atleast_2d(X)\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        prediction = np.hstack((ones.T, X))\n",
    "\n",
    "        for weight_matrix in self.weights:\n",
    "            prediction = self.activation(np.matmul(prediction, weight_matrix))\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028ab7f2-a527-4a8e-b162-5dab29ce2769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data gates\n",
    "xor_gate = pd.DataFrame([[0,0,0],[1,0,1],[0,1,1],[1,1,0]], columns = ['x1', 'x2', 'y'])\n",
    "and_gate = pd.DataFrame([[1,1,1],[1,0,0],[0,1,0],[0,0,0]], columns = ['x1', 'x2', 'y'])\n",
    "or_gate = pd.DataFrame([[1,1,1],[1,0,1],[0,1,1],[0,0,0]], columns = ['x1', 'x2', 'y'])\n",
    "X = xor_gate[['x1', 'x2']].to_numpy()\n",
    "y = xor_gate[['y']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f941bb9-98d8-4d28-8df0-d7e0fb4bba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beer_fun_example\n",
    "beer_fun_data = pd.read_csv('./regression_example_data.csv')\n",
    "X = beer_fun_data[['beer_cons']].to_numpy()\n",
    "y = beer_fun_data[['fun']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebcd7ac-81f1-4e5a-a312-144307130036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNet([2,2,1])\n",
    "history = nn.fit(X, y, l_rate=0.1, epochs = 30000, print_freq=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fa845b-906e-4285-90d4-89fb37e49d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "history_df = pd.DataFrame(history, columns=['epoch', 'MSE', 'MAE'])\n",
    "history_df.plot(x='epoch', y=['MAE'])\n",
    "history_df.tail(int(len(history_df.index)/1.5)).plot(x='epoch', y='MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1184c6-4b15-4684-bb35-52baf2450a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create test data\n",
    "X_test = np.atleast_2d(np.linspace(0,1,1001,1)).T\n",
    "Y=nn.predict(X_test)\n",
    "\n",
    "predictions = pd.DataFrame([X_test.flatten(),Y.flatten()]).T\n",
    "predictions.columns = ['beer_cons', 'fun']\n",
    "\n",
    "training_data = pd.DataFrame([X.flatten(),y.flatten()]).T\n",
    "training_data.columns = ['beer_cons', 'fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1977459-c0b4-44cf-962b-1b97a9bf062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display predictions\n",
    "ax = training_data.plot(kind='scatter', x= 'beer_cons', y='fun')\n",
    "predictions.plot(kind='line', x= 'beer_cons', y='fun', ax = ax, color='orange')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
