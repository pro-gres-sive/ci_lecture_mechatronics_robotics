{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e2d7b7-0fa3-4dd8-b51f-016ea5c05a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #library for visualizing data\n",
    "%matplotlib widget \n",
    "#setting for jupyter lab\n",
    "plt.rcParams['figure.figsize'] = [10, 5] #setting figure size (plots)\n",
    "\n",
    "import pandas as pd  # (software library for data analysis and manipulation, https://pandas.pydata.org/docs/)\n",
    "import numpy as np  # (software library for matrix multiplications, https://numpy.org/doc/)\n",
    "import statistics as stats  # (python module for statistic calculations, https://docs.python.org/3/library/statistics.html)\n",
    "import time #python time module\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def tanh_deriv(x):\n",
    "    return 1 - x ** 2\n",
    "\n",
    "\n",
    "class NeuralNet:\n",
    "\n",
    "    history = []\n",
    "    layer_topology = []\n",
    "\n",
    "    \n",
    "    \n",
    "    def __init__(self, layers, activation='tanh', print_model_info=True):\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = sigmoid\n",
    "            self.activation_prime = sigmoid_deriv\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = tanh\n",
    "            self.activation_prime = tanh_deriv\n",
    "\n",
    "        self.layers = layers\n",
    "\n",
    "        # Set weights for each layer\n",
    "        self.weights = []\n",
    "        for i in range(0, len(layers) - 1):\n",
    "            additional_column = 1 if i < len(layers) - 2 else 0\n",
    "            r = np.random.randint(-200, 200, (layers[i] + 1, layers[i + 1] + additional_column)) * 0.001\n",
    "            self.weights.append(r)\n",
    "\n",
    "        if print_model_info:\n",
    "            self.print_model_info()\n",
    "\n",
    "            \n",
    "            \n",
    "    def print_model_info(self):\n",
    "        print('Model: \\n')\n",
    "\n",
    "        layers = self.layers\n",
    "        max_nodes = max(layers)\n",
    "        for i, layer in enumerate(layers):\n",
    "            diff = abs(max_nodes - layer)\n",
    "            output = ''\n",
    "            for k in range(round(diff + 0.5 / 2)):\n",
    "                output += ' '\n",
    "            for j in range(layer):\n",
    "                output += ' O'\n",
    "            for k in range(round(diff + 5)):\n",
    "                output += ' '\n",
    "            if i == 0:\n",
    "                output += f'{layer} Input(s)'\n",
    "            elif i == len(layers) - 1:\n",
    "                output += f'{layer} Output(s)'\n",
    "            else:\n",
    "                output += f'{layer} Node(s)'\n",
    "            print(output)\n",
    "\n",
    "        print('\\nActivation:', str(self.activation))\n",
    "\n",
    "        weight_count = 0\n",
    "        for weight in self.weights:\n",
    "            weight_count += weight.shape[0] * weight.shape[1]\n",
    "\n",
    "        print(f'{len(layers)} Layers')\n",
    "        print(f'{weight_count} trainable parameters.\\n\\n')\n",
    "\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y, l_rate=0.2, epochs=100000, print_freq=100):\n",
    "        t_0 = time.perf_counter()\n",
    "\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.hstack((ones.T, X))  # stack ones for bias\n",
    "\n",
    "        history = []\n",
    "\n",
    "        for k in range(epochs):\n",
    "            t_0_epoch = time.perf_counter()\n",
    "            for i, row in enumerate(X):  # loop through every training data sample\n",
    "\n",
    "                # FEED FORWARD\n",
    "                layer_activations = [row]\n",
    "                for w_i in range(len(self.weights)):\n",
    "                    dot_value = np.matmul(layer_activations[w_i], self.weights[w_i])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    layer_activations.append(activation)\n",
    "\n",
    "                # 1: Output Layer\n",
    "                nn_result = layer_activations[-1]  # last item in our layer_activations is the output of our network\n",
    "                error = y[i] - nn_result\n",
    "\n",
    "                deltas = [error * self.activation_prime(layer_activations[-1])]\n",
    "\n",
    "                # 2: Backpropagation Hidden Layers\n",
    "                for la_i in range(len(layer_activations) - 2, 0, -1):  # iterate backwards through layer_activations and weights\n",
    "                    ##compute delta based on previous examined layers deltas and save in list\n",
    "                    deltas.append(np.matmul(deltas[-1], self.weights[la_i].T) * self.activation_prime(layer_activations[la_i]))\n",
    "                deltas.reverse()  # invert order of delta list\n",
    "\n",
    "                # 3: Gradient calculation and weight update\n",
    "                for w_i in range(len(self.weights)):\n",
    "                    layer_activation = np.atleast_2d(layer_activations[w_i])\n",
    "                    delta = np.atleast_2d(deltas[w_i])\n",
    "                    gradient = np.matmul(layer_activation.T, delta)\n",
    "                    self.weights[w_i] += l_rate * gradient\n",
    "\n",
    "            # performance control\n",
    "            Y_pred = nn.predict(X[:, 1:])\n",
    "            error = Y_pred - y.reshape(len(y), 1)\n",
    "            mse = (error ** 2).mean()\n",
    "            mae = np.abs(error).mean()\n",
    "\n",
    "            history.append([k, mse, mae])\n",
    "\n",
    "            # print output\n",
    "            #? add validation data\n",
    "            if k % print_freq == 0:\n",
    "                t_1_epoch = time.perf_counter()\n",
    "                time_delta_epochs = t_1_epoch - t_0_epoch\n",
    "                mean_time_delta_epochs_ms = round((time_delta_epochs / print_freq) * 1000, 4)\n",
    "                print(f'Epochs: {k}  -  MSE: {round(mse,4)}  -  MAE: {round(mae,4)}  -  Mean Time per Epoch: {mean_time_delta_epochs_ms} ms')\n",
    "\n",
    "        self.history = history\n",
    "        print(f'\\nTraining finished. Time consumed: {round(time.perf_counter() - t_0, 2)} s')\n",
    "        return history\n",
    "\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.atleast_2d(X)\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        prediction = np.hstack((ones.T, X))\n",
    "\n",
    "        for weight_matrix in self.weights:\n",
    "            prediction = self.activation(np.matmul(prediction, weight_matrix))\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "028ab7f2-a527-4a8e-b162-5dab29ce2769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data gates\n",
    "xor_gate = pd.DataFrame([[0,0,0],[1,0,1],[0,1,1],[1,1,0]], columns = ['x1', 'x2', 'y'])\n",
    "and_gate = pd.DataFrame([[1,1,1],[1,0,0],[0,1,0],[0,0,0]], columns = ['x1', 'x2', 'y'])\n",
    "or_gate = pd.DataFrame([[1,1,1],[1,0,1],[0,1,1],[0,0,0]], columns = ['x1', 'x2', 'y'])\n",
    "X = xor_gate[['x1', 'x2']].to_numpy()\n",
    "y = xor_gate[['y']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f941bb9-98d8-4d28-8df0-d7e0fb4bba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beer_fun_example\n",
    "beer_fun_data = pd.read_csv('./regression_example_data.csv')\n",
    "X = beer_fun_data[['beer_cons']].to_numpy()\n",
    "y = beer_fun_data[['fun']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ebcd7ac-81f1-4e5a-a312-144307130036",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \n",
      "\n",
      "      O          1 Input(s)\n",
      "     O O         2 Node(s)\n",
      "    O O O        3 Node(s)\n",
      "   O O O O       4 Node(s)\n",
      "  O O O O O      5 Node(s)\n",
      " O O O O O O     6 Node(s)\n",
      " O O O O O O     6 Node(s)\n",
      "      O          1 Output(s)\n",
      "\n",
      "Activation: <function tanh at 0x7ff785b00af0>\n",
      "8 Layers\n",
      "166 trainable parameters.\n",
      "\n",
      "\n",
      "Epochs: 0  -  MSE: 0.2496  -  MAE: 0.3505  -  Mean Time per Epoch: 0.0305 ms\n",
      "Epochs: 250  -  MSE: 0.0087  -  MAE: 0.0723  -  Mean Time per Epoch: 0.0286 ms\n",
      "Epochs: 500  -  MSE: 0.0077  -  MAE: 0.0666  -  Mean Time per Epoch: 0.0273 ms\n",
      "Epochs: 750  -  MSE: 0.0074  -  MAE: 0.0638  -  Mean Time per Epoch: 0.0273 ms\n",
      "Epochs: 1000  -  MSE: 0.0072  -  MAE: 0.062  -  Mean Time per Epoch: 0.0269 ms\n",
      "Epochs: 1250  -  MSE: 0.007  -  MAE: 0.061  -  Mean Time per Epoch: 0.0272 ms\n",
      "Epochs: 1500  -  MSE: 0.007  -  MAE: 0.0604  -  Mean Time per Epoch: 0.0282 ms\n",
      "Epochs: 1750  -  MSE: 0.0069  -  MAE: 0.0601  -  Mean Time per Epoch: 0.0273 ms\n",
      "Epochs: 2000  -  MSE: 0.0069  -  MAE: 0.0601  -  Mean Time per Epoch: 0.0271 ms\n",
      "Epochs: 2250  -  MSE: 0.0069  -  MAE: 0.0605  -  Mean Time per Epoch: 0.027 ms\n",
      "Epochs: 2500  -  MSE: 0.0069  -  MAE: 0.0613  -  Mean Time per Epoch: 0.031 ms\n",
      "Epochs: 2750  -  MSE: 0.007  -  MAE: 0.062  -  Mean Time per Epoch: 0.0286 ms\n",
      "Epochs: 3000  -  MSE: 0.0069  -  MAE: 0.0622  -  Mean Time per Epoch: 0.0272 ms\n",
      "Epochs: 3250  -  MSE: 0.0068  -  MAE: 0.0618  -  Mean Time per Epoch: 0.0273 ms\n",
      "Epochs: 3500  -  MSE: 0.0066  -  MAE: 0.0605  -  Mean Time per Epoch: 0.0283 ms\n",
      "Epochs: 3750  -  MSE: 0.0063  -  MAE: 0.0586  -  Mean Time per Epoch: 0.0272 ms\n",
      "Epochs: 4000  -  MSE: 0.0061  -  MAE: 0.0567  -  Mean Time per Epoch: 0.0279 ms\n",
      "Epochs: 4250  -  MSE: 0.0059  -  MAE: 0.0551  -  Mean Time per Epoch: 0.028 ms\n",
      "Epochs: 4500  -  MSE: 0.0058  -  MAE: 0.0539  -  Mean Time per Epoch: 0.0294 ms\n",
      "Epochs: 4750  -  MSE: 0.0057  -  MAE: 0.0532  -  Mean Time per Epoch: 0.0282 ms\n",
      "Epochs: 5000  -  MSE: 0.0056  -  MAE: 0.0526  -  Mean Time per Epoch: 0.0279 ms\n",
      "Epochs: 5250  -  MSE: 0.0055  -  MAE: 0.052  -  Mean Time per Epoch: 0.0282 ms\n",
      "Epochs: 5500  -  MSE: 0.0054  -  MAE: 0.0515  -  Mean Time per Epoch: 0.0284 ms\n",
      "Epochs: 5750  -  MSE: 0.0054  -  MAE: 0.0513  -  Mean Time per Epoch: 0.0278 ms\n",
      "Epochs: 6000  -  MSE: 0.0053  -  MAE: 0.0515  -  Mean Time per Epoch: 0.0285 ms\n",
      "Epochs: 6250  -  MSE: 0.0053  -  MAE: 0.0516  -  Mean Time per Epoch: 0.028 ms\n",
      "Epochs: 6500  -  MSE: 0.0053  -  MAE: 0.0517  -  Mean Time per Epoch: 0.028 ms\n",
      "Epochs: 6750  -  MSE: 0.0053  -  MAE: 0.052  -  Mean Time per Epoch: 0.0278 ms\n",
      "Epochs: 7000  -  MSE: 0.0053  -  MAE: 0.0523  -  Mean Time per Epoch: 0.0279 ms\n",
      "Epochs: 7250  -  MSE: 0.0054  -  MAE: 0.0527  -  Mean Time per Epoch: 0.0279 ms\n",
      "Epochs: 7500  -  MSE: 0.0054  -  MAE: 0.0531  -  Mean Time per Epoch: 0.0285 ms\n",
      "Epochs: 7750  -  MSE: 0.0054  -  MAE: 0.0535  -  Mean Time per Epoch: 0.0291 ms\n",
      "Epochs: 8000  -  MSE: 0.0055  -  MAE: 0.0538  -  Mean Time per Epoch: 0.028 ms\n",
      "Epochs: 8250  -  MSE: 0.0055  -  MAE: 0.0541  -  Mean Time per Epoch: 0.028 ms\n",
      "Epochs: 8500  -  MSE: 0.0055  -  MAE: 0.0543  -  Mean Time per Epoch: 0.0282 ms\n",
      "Epochs: 8750  -  MSE: 0.0056  -  MAE: 0.0546  -  Mean Time per Epoch: 0.029 ms\n",
      "Epochs: 9000  -  MSE: 0.0056  -  MAE: 0.0548  -  Mean Time per Epoch: 0.0295 ms\n",
      "Epochs: 9250  -  MSE: 0.0056  -  MAE: 0.055  -  Mean Time per Epoch: 0.0289 ms\n",
      "Epochs: 9500  -  MSE: 0.0057  -  MAE: 0.0551  -  Mean Time per Epoch: 0.0285 ms\n",
      "Epochs: 9750  -  MSE: 0.0057  -  MAE: 0.0553  -  Mean Time per Epoch: 0.0287 ms\n",
      "Epochs: 10000  -  MSE: 0.0057  -  MAE: 0.0555  -  Mean Time per Epoch: 0.0288 ms\n",
      "Epochs: 10250  -  MSE: 0.0057  -  MAE: 0.0556  -  Mean Time per Epoch: 0.0289 ms\n",
      "Epochs: 10500  -  MSE: 0.0057  -  MAE: 0.0557  -  Mean Time per Epoch: 0.0298 ms\n",
      "Epochs: 10750  -  MSE: 0.0058  -  MAE: 0.0558  -  Mean Time per Epoch: 0.0286 ms\n",
      "Epochs: 11000  -  MSE: 0.0058  -  MAE: 0.056  -  Mean Time per Epoch: 0.0289 ms\n",
      "Epochs: 11250  -  MSE: 0.0058  -  MAE: 0.0561  -  Mean Time per Epoch: 0.0288 ms\n",
      "Epochs: 11500  -  MSE: 0.0058  -  MAE: 0.0562  -  Mean Time per Epoch: 0.0292 ms\n",
      "Epochs: 11750  -  MSE: 0.0058  -  MAE: 0.0563  -  Mean Time per Epoch: 0.03 ms\n",
      "Epochs: 12000  -  MSE: 0.0059  -  MAE: 0.0564  -  Mean Time per Epoch: 0.0292 ms\n",
      "Epochs: 12250  -  MSE: 0.0059  -  MAE: 0.0565  -  Mean Time per Epoch: 0.0288 ms\n",
      "Epochs: 12500  -  MSE: 0.0059  -  MAE: 0.0566  -  Mean Time per Epoch: 0.0289 ms\n",
      "Epochs: 12750  -  MSE: 0.0059  -  MAE: 0.0567  -  Mean Time per Epoch: 0.0291 ms\n",
      "Epochs: 13000  -  MSE: 0.0059  -  MAE: 0.0568  -  Mean Time per Epoch: 0.0293 ms\n",
      "Epochs: 13250  -  MSE: 0.0059  -  MAE: 0.0569  -  Mean Time per Epoch: 0.0297 ms\n",
      "Epochs: 13500  -  MSE: 0.006  -  MAE: 0.057  -  Mean Time per Epoch: 0.0289 ms\n",
      "Epochs: 13750  -  MSE: 0.006  -  MAE: 0.0571  -  Mean Time per Epoch: 0.029 ms\n",
      "Epochs: 14000  -  MSE: 0.006  -  MAE: 0.0572  -  Mean Time per Epoch: 0.0289 ms\n",
      "Epochs: 14250  -  MSE: 0.006  -  MAE: 0.0573  -  Mean Time per Epoch: 0.0293 ms\n",
      "Epochs: 14500  -  MSE: 0.006  -  MAE: 0.0574  -  Mean Time per Epoch: 0.0292 ms\n",
      "Epochs: 14750  -  MSE: 0.006  -  MAE: 0.0575  -  Mean Time per Epoch: 0.0298 ms\n",
      "Epochs: 15000  -  MSE: 0.0061  -  MAE: 0.0576  -  Mean Time per Epoch: 0.0299 ms\n",
      "Epochs: 15250  -  MSE: 0.0061  -  MAE: 0.0577  -  Mean Time per Epoch: 0.0292 ms\n",
      "Epochs: 15500  -  MSE: 0.0061  -  MAE: 0.0579  -  Mean Time per Epoch: 0.0292 ms\n",
      "Epochs: 15750  -  MSE: 0.0061  -  MAE: 0.058  -  Mean Time per Epoch: 0.0296 ms\n",
      "Epochs: 16000  -  MSE: 0.0061  -  MAE: 0.0582  -  Mean Time per Epoch: 0.0297 ms\n",
      "Epochs: 16250  -  MSE: 0.0062  -  MAE: 0.0583  -  Mean Time per Epoch: 0.0293 ms\n",
      "Epochs: 16500  -  MSE: 0.0062  -  MAE: 0.0584  -  Mean Time per Epoch: 0.0297 ms\n",
      "Epochs: 16750  -  MSE: 0.0062  -  MAE: 0.0586  -  Mean Time per Epoch: 0.0292 ms\n",
      "Epochs: 17000  -  MSE: 0.0062  -  MAE: 0.0587  -  Mean Time per Epoch: 0.0294 ms\n",
      "Epochs: 17250  -  MSE: 0.0062  -  MAE: 0.0588  -  Mean Time per Epoch: 0.0302 ms\n",
      "Epochs: 17500  -  MSE: 0.0063  -  MAE: 0.059  -  Mean Time per Epoch: 0.0305 ms\n",
      "Epochs: 17750  -  MSE: 0.0063  -  MAE: 0.0591  -  Mean Time per Epoch: 0.0308 ms\n",
      "Epochs: 18000  -  MSE: 0.0063  -  MAE: 0.0592  -  Mean Time per Epoch: 0.0311 ms\n",
      "Epochs: 18250  -  MSE: 0.0063  -  MAE: 0.0594  -  Mean Time per Epoch: 0.0294 ms\n",
      "Epochs: 18500  -  MSE: 0.0063  -  MAE: 0.0595  -  Mean Time per Epoch: 0.0295 ms\n",
      "Epochs: 18750  -  MSE: 0.0063  -  MAE: 0.0596  -  Mean Time per Epoch: 0.0302 ms\n",
      "Epochs: 19000  -  MSE: 0.0064  -  MAE: 0.0598  -  Mean Time per Epoch: 0.03 ms\n",
      "Epochs: 19250  -  MSE: 0.0064  -  MAE: 0.0599  -  Mean Time per Epoch: 0.0297 ms\n",
      "Epochs: 19500  -  MSE: 0.0064  -  MAE: 0.06  -  Mean Time per Epoch: 0.0297 ms\n",
      "Epochs: 19750  -  MSE: 0.0064  -  MAE: 0.0601  -  Mean Time per Epoch: 0.0292 ms\n",
      "Epochs: 20000  -  MSE: 0.0064  -  MAE: 0.0603  -  Mean Time per Epoch: 0.0297 ms\n",
      "Epochs: 20250  -  MSE: 0.0064  -  MAE: 0.0604  -  Mean Time per Epoch: 0.0297 ms\n",
      "Epochs: 20500  -  MSE: 0.0065  -  MAE: 0.0605  -  Mean Time per Epoch: 0.0312 ms\n",
      "Epochs: 20750  -  MSE: 0.0065  -  MAE: 0.0606  -  Mean Time per Epoch: 0.0306 ms\n",
      "Epochs: 21000  -  MSE: 0.0065  -  MAE: 0.0607  -  Mean Time per Epoch: 0.0302 ms\n",
      "Epochs: 21250  -  MSE: 0.0065  -  MAE: 0.0608  -  Mean Time per Epoch: 0.0296 ms\n",
      "Epochs: 21500  -  MSE: 0.0065  -  MAE: 0.0609  -  Mean Time per Epoch: 0.0295 ms\n",
      "Epochs: 21750  -  MSE: 0.0065  -  MAE: 0.061  -  Mean Time per Epoch: 0.0296 ms\n",
      "Epochs: 22000  -  MSE: 0.0065  -  MAE: 0.0611  -  Mean Time per Epoch: 0.0294 ms\n",
      "Epochs: 22250  -  MSE: 0.0065  -  MAE: 0.0612  -  Mean Time per Epoch: 0.0301 ms\n",
      "Epochs: 22500  -  MSE: 0.0066  -  MAE: 0.0613  -  Mean Time per Epoch: 0.0306 ms\n",
      "Epochs: 22750  -  MSE: 0.0066  -  MAE: 0.0614  -  Mean Time per Epoch: 0.0299 ms\n",
      "Epochs: 23000  -  MSE: 0.0066  -  MAE: 0.0614  -  Mean Time per Epoch: 0.0295 ms\n",
      "Epochs: 23250  -  MSE: 0.0066  -  MAE: 0.0615  -  Mean Time per Epoch: 0.0293 ms\n",
      "Epochs: 23500  -  MSE: 0.0066  -  MAE: 0.0616  -  Mean Time per Epoch: 0.0296 ms\n",
      "Epochs: 23750  -  MSE: 0.0066  -  MAE: 0.0616  -  Mean Time per Epoch: 0.0295 ms\n",
      "Epochs: 24000  -  MSE: 0.0066  -  MAE: 0.0617  -  Mean Time per Epoch: 0.0296 ms\n",
      "Epochs: 24250  -  MSE: 0.0066  -  MAE: 0.0617  -  Mean Time per Epoch: 0.0301 ms\n",
      "Epochs: 24500  -  MSE: 0.0066  -  MAE: 0.0618  -  Mean Time per Epoch: 0.0297 ms\n",
      "Epochs: 24750  -  MSE: 0.0066  -  MAE: 0.0618  -  Mean Time per Epoch: 0.0302 ms\n",
      "Epochs: 25000  -  MSE: 0.0066  -  MAE: 0.0619  -  Mean Time per Epoch: 0.0297 ms\n",
      "Epochs: 25250  -  MSE: 0.0066  -  MAE: 0.0619  -  Mean Time per Epoch: 0.0298 ms\n",
      "Epochs: 25500  -  MSE: 0.0066  -  MAE: 0.0619  -  Mean Time per Epoch: 0.0295 ms\n",
      "Epochs: 25750  -  MSE: 0.0066  -  MAE: 0.062  -  Mean Time per Epoch: 0.0301 ms\n",
      "Epochs: 26000  -  MSE: 0.0066  -  MAE: 0.062  -  Mean Time per Epoch: 0.0296 ms\n",
      "Epochs: 26250  -  MSE: 0.0066  -  MAE: 0.062  -  Mean Time per Epoch: 0.031 ms\n",
      "Epochs: 26500  -  MSE: 0.0066  -  MAE: 0.062  -  Mean Time per Epoch: 0.0298 ms\n",
      "Epochs: 26750  -  MSE: 0.0066  -  MAE: 0.0621  -  Mean Time per Epoch: 0.0297 ms\n",
      "Epochs: 27000  -  MSE: 0.0066  -  MAE: 0.0621  -  Mean Time per Epoch: 0.0295 ms\n",
      "Epochs: 27250  -  MSE: 0.0066  -  MAE: 0.0621  -  Mean Time per Epoch: 0.0301 ms\n",
      "Epochs: 27500  -  MSE: 0.0066  -  MAE: 0.0621  -  Mean Time per Epoch: 0.0299 ms\n",
      "Epochs: 27750  -  MSE: 0.0066  -  MAE: 0.0621  -  Mean Time per Epoch: 0.0297 ms\n",
      "Epochs: 28000  -  MSE: 0.0066  -  MAE: 0.0622  -  Mean Time per Epoch: 0.0295 ms\n",
      "Epochs: 28250  -  MSE: 0.0066  -  MAE: 0.0622  -  Mean Time per Epoch: 0.0308 ms\n",
      "Epochs: 28500  -  MSE: 0.0066  -  MAE: 0.0622  -  Mean Time per Epoch: 0.0297 ms\n",
      "Epochs: 28750  -  MSE: 0.0066  -  MAE: 0.0622  -  Mean Time per Epoch: 0.0294 ms\n",
      "Epochs: 29000  -  MSE: 0.0066  -  MAE: 0.0622  -  Mean Time per Epoch: 0.0296 ms\n",
      "Epochs: 29250  -  MSE: 0.0066  -  MAE: 0.0622  -  Mean Time per Epoch: 0.0295 ms\n",
      "Epochs: 29500  -  MSE: 0.0066  -  MAE: 0.0623  -  Mean Time per Epoch: 0.0295 ms\n",
      "Epochs: 29750  -  MSE: 0.0066  -  MAE: 0.0623  -  Mean Time per Epoch: 0.0297 ms\n",
      "\n",
      "Training finished. Time consumed: 219.27 s\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNet([1,2,3,4,5,6,6,1])\n",
    "history = nn.fit(X, y, l_rate=0.2, epochs = 30000, print_freq=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09fa845b-906e-4285-90d4-89fb37e49d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39e410238444d4b886efcd2af8aab9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98b41ae14f544f88459e985f2b041f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='epoch'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "history_df = pd.DataFrame(history, columns=['epoch', 'MSE', 'MAE'])\n",
    "history_df.plot(x='epoch', y=['MAE'])\n",
    "history_df.tail(int(len(history_df.index)/1.5)).plot(x='epoch', y='MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1184c6-4b15-4684-bb35-52baf2450a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create test data\n",
    "X_test = np.atleast_2d(np.linspace(0,1,1001,1)).T\n",
    "Y=nn.predict(X_test)\n",
    "\n",
    "predictions = pd.DataFrame([X_test.flatten(),Y.flatten()]).T\n",
    "predictions.columns = ['beer_cons', 'fun']\n",
    "\n",
    "training_data = pd.DataFrame([X.flatten(),y.flatten()]).T\n",
    "training_data.columns = ['beer_cons', 'fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1977459-c0b4-44cf-962b-1b97a9bf062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display predictions\n",
    "ax = training_data.plot(kind='scatter', x= 'beer_cons', y='fun')\n",
    "predictions.plot(kind='line', x= 'beer_cons', y='fun', ax = ax, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e1785-7f69-45bd-ba0e-12f373d7eefe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
