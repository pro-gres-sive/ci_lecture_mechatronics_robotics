{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acbcf38f-90ea-42a2-90ca-e9c32a769288",
   "metadata": {},
   "source": [
    "# Lecture 1\n",
    "In lecture 1 we've learned, that a perceptron can be used as linear classifier.\n",
    "\n",
    "![Schema of a perceptron](./img/perceptron.jpg \"Title\")\n",
    "\n",
    "We used a single perceptron to predict whether it's a good day to go swimming or not - based on an input vector with the binary inputs temperature, sunshine and friends.\n",
    "\n",
    "Below are the weights and bias (as definded in the lecture) for this classification problem. Further, you will find a function \"perceptron()\" which takes an input_vector, weight_vector and a bias as inputs and outputs the prediction.\n",
    "\n",
    "## Task 1\n",
    "Try changing inputs, weights and bias of the perceptron to find how those changes affect the prediction.\n",
    "\n",
    "## Task 2\n",
    "Imagine you're building a computer out of binary logic gates (https://en.wikipedia.org/wiki/Logic_gate) and you want to use perceptrons as the smallest building blocks to build it.\n",
    "\n",
    "Change the perceptrons inputs, weights and bias to implement the logic gates \"AND\", \"NAND\", \"OR\" and \"NOR\"\n",
    "\n",
    "# Task 3\n",
    "Now try to implement the logic gates \"XAND\" and \"XOR\" by changing the perceptrons parameters. Do you encounter any difficulties doing that? If yes, why is that?\n",
    "\n",
    "# Task 4\n",
    "Take a different approach implementing the logic gates \"XAND\" and \"XOR\" by combining logic gates you modeled in Task 2. (=> Implementing a Multilayer-Perceptron [MLP]).\n",
    "\n",
    "![Schema of a multilayer perceptron](./img/mlp.png \"Title\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "891887bc-d753-4096-af03-6032e2396a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31de5124-2031-4627-9de0-4533e7823839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters, weights and bias used in the lecture example\n",
    "\n",
    "inputs = pd.Series([0, 1, 0], index=['Temp', 'Sun', 'Friends'])\n",
    "weights = pd.Series([3, 2, 1], index=['Temp_w', 'Sun_w', 'Friends_w'])\n",
    "bias = -2\n",
    "\n",
    "\n",
    "# functions\n",
    "\n",
    "\n",
    "def step(step_input):\n",
    "    '''simple step function\n",
    "    f(<=0) -> output = 0,\n",
    "    f(>0) -> ouput = 1'''\n",
    "\n",
    "    output = 0\n",
    "\n",
    "    if step_input > 0:\n",
    "        output = 1\n",
    "    return output\n",
    "\n",
    "\n",
    "# alternative to custom implementation of step function:\n",
    "# np.heaviside(input, 0) # https://numpy.org/doc/stable/reference/generated/numpy.heaviside.html\n",
    "\n",
    "\n",
    "def perceptron(inputs, weights, bias):\n",
    "    '''compute perceptron output for given inputs, weights, and bias'''\n",
    "    result = np.matmul(inputs.to_numpy(), weights.to_numpy()) + bias\n",
    "    return step(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe2a5a8-b70c-4e0f-a2ca-492dbe90d356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# output\n",
    "perceptron_output = perceptron(inputs, weights, bias) #get perceptrons output\n",
    "print(perceptron_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd7eb1-dbd0-4a56-9af5-cd23dcd6e1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
